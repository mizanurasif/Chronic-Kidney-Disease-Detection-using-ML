{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189d161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e399ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        int64\n",
       "bp         int64\n",
       "sg       float64\n",
       "al         int64\n",
       "su         int64\n",
       "rbc        int64\n",
       "pc         int64\n",
       "pcc        int64\n",
       "ba         int64\n",
       "bgr        int64\n",
       "bu         int64\n",
       "sc         int64\n",
       "sod      float64\n",
       "pot      float64\n",
       "hemo     float64\n",
       "pcv        int64\n",
       "wbcc       int64\n",
       "rbcc     float64\n",
       "htn        int64\n",
       "dm         int64\n",
       "cad        int64\n",
       "appet      int64\n",
       "pe         int64\n",
       "ane        int64\n",
       "class      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"E:\\3.2\\software project\\kidney_Disease_Pre_processed.csv\")\n",
    "#df= df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "\n",
    "df= df.drop(\"Unnamed: 0\",axis=1)\n",
    "x = df.drop(\"class\",axis=1)\n",
    "y= df[\"class\"]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4db4f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C= 100, gamma= 'scale', kernel= 'linear')\n",
    "knn = KNeighborsClassifier(algorithm = 'ball_tree', n_jobs= 1, n_neighbors= 6, weights= 'uniform')\n",
    "lr= LogisticRegression(C = 100, max_iter = 2000, penalty= 'l2', solver = 'newton-cg')\n",
    "xgb = XGBClassifier(colsample_bytree = 0.5, gamma= 0.0, learning_rate = 0.15, max_depth = 5, min_child_weight = 1)\n",
    "rf = RandomForestClassifier(bootstrap =True, criterion = 'entropy', max_features = 'auto', min_samples_leaf = 1, min_samples_split = 4, n_estimators = 100)\n",
    "adab = AdaBoostClassifier(base_estimator=GaussianNB(),learning_rate = 0.2, n_estimators = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e938fcd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy SVM: 0.981\n",
      "Test Accuracy SVM: 0.988\n",
      "train Accuracy KNN: 0.834\n",
      "Test Accuracy KNN: 0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy LR: 1.000\n",
      "Test Accuracy LR: 0.988\n",
      "[21:57:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy XGB: 1.000\n",
      "Test Accuracy XGB: 1.000\n",
      "train Accuracy RF: 1.000\n",
      "Test Accuracy  RF: 1.000\n",
      "train Accuracy ADAB: 1.000\n",
      "Test Accuracy ADAB: 0.988\n"
     ]
    }
   ],
   "source": [
    "svm.fit(x_train,y_train)\n",
    "print(\"train Accuracy SVM: %0.3f\" % svm.score(x_train,y_train))\n",
    "print(\"Test Accuracy SVM: %0.3f\" % svm.score(x_test,y_test))\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "print(\"train Accuracy KNN: %0.3f\" % knn.score(x_train,y_train))\n",
    "print(\"Test Accuracy KNN: %0.3f\" % knn.score(x_test,y_test))\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"train Accuracy LR: %0.3f\" % lr.score(x_train,y_train))\n",
    "print(\"Test Accuracy LR: %0.3f\" % lr.score(x_test,y_test))\n",
    "\n",
    "xgb.fit(x_train,y_train)\n",
    "print(\"train Accuracy XGB: %0.3f\" % xgb.score(x_train,y_train))\n",
    "print(\"Test Accuracy XGB: %0.3f\" % xgb.score(x_test,y_test))\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "print(\"train Accuracy RF: %0.3f\" % rf.score(x_train,y_train))\n",
    "print(\"Test Accuracy  RF: %0.3f\" % rf.score(x_test,y_test))\n",
    "\n",
    "adab.fit(x_train,y_train)\n",
    "print(\"train Accuracy ADAB: %0.3f\" % adab.score(x_train,y_train))\n",
    "print(\"Test Accuracy ADAB: %0.3f\" % adab.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddb0f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf=EnsembleVoteClassifier(clfs=[svm,lr,xgb,rf,adab],weights=[1,1,1,1,1])\n",
    "labels=['support_vector_machine_model','Logistic Regression','XGB Model','Random Forest','Ada boost GaussianNB','EVC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9c38b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Accuracy: 0.98750 [support_vector_machine_model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Accuracy: 0.98750 [Logistic Regression]\n",
      "[22:03:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Accuracy: 1.00000 [XGB Model]\n",
      "validation Accuracy: 0.98750 [Random Forest]\n",
      "validation Accuracy: 0.98750 [Ada boost GaussianNB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\mizan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "validation Accuracy: 0.98750 [EVC]\n",
      "Test Accuracy: 0.98750\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([svm,lr,xgb,rf,adab,eclf],labels):\n",
    "   clf.fit(x_train,y_train)\n",
    "   print(\"validation Accuracy: %0.5f [%s]\" % (clf.score(x_test,y_test),label))\n",
    "print(\"Test Accuracy: %0.5f\" % eclf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
